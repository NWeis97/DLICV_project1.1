{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code will run on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /zhome/0c/5/127579/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "/zhome/0c/5/127579/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:14: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  \"pytorch_quantization module not found, quantization will not be available\"\n",
      "/zhome/0c/5/127579/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:18: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  \"pytorch_quantization module not found, quantization will not be available\"\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/zhome/0c/5/127579/Desktop/DeepLearningComputerVision/DLICV_project1.1/src/models/models/EfficientNet_WithAugs-False_WithNorm-False_LR-0.001_NumEpochs-10.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_128954/3933221142.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mefficientnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# Freeze parameters for pretrained model (to avoid overfitting)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mefficientnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/models/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0mefficientnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mefficientnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DeepLearningComputerVision/env/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DeepLearningComputerVision/env/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DeepLearningComputerVision/env/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/zhome/0c/5/127579/Desktop/DeepLearningComputerVision/DLICV_project1.1/src/models/models/EfficientNet_WithAugs-False_WithNorm-False_LR-0.001_NumEpochs-10.pt'"
     ]
    }
   ],
   "source": [
    "# Import \n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pdb\n",
    "\n",
    "# settings\n",
    "torch.manual_seed(1234)\n",
    "with_augs = False\n",
    "lr = 0.001\n",
    "with_norm = False\n",
    "num_epochs = 10\n",
    "\n",
    "name = \"EfficientNet_WithAugs-\"+str(with_augs)+\"_WithNorm-\"+str(with_norm)+\"_LR-\"+str(lr)+\"_NumEpochs-\"+str(num_epochs)\n",
    "\n",
    "\n",
    "# Get CUDA\n",
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define Hotdog data class\n",
    "class Hotdog_NotHotdog(torch.utils.data.Dataset):\n",
    "    def __init__(self, train, transform, data_path='/dtu/datasets1/02514/hotdog_nothotdog'):\n",
    "        'Initialization'\n",
    "        self.transform = transform\n",
    "        data_path = os.path.join(data_path, 'train' if train else 'test')\n",
    "        image_classes = [os.path.split(d)[1] for d in glob.glob(data_path +'/*') if os.path.isdir(d)]\n",
    "        image_classes.sort()\n",
    "        self.name_to_label = {c: id for id, c in enumerate(image_classes)}\n",
    "        self.image_paths = glob.glob(data_path + '/*/*.jpg')\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Returns the total number of samples'\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        'Generates one sample of data'\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        c = os.path.split(os.path.split(image_path)[0])[1]\n",
    "        y = self.name_to_label[c]\n",
    "        X = self.transform(image)\n",
    "        return X, y\n",
    "\n",
    "\n",
    "# Load data\n",
    "size = 224\n",
    "train_test_transform = transforms.Compose([transforms.Resize((size, size)), \n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5226-0.5226*(1.0*with_norm), 0.4412-0.4412*(1.0*with_norm), 0.3585-0.3585*(1.0*with_norm)), \n",
    "                                                         (0.0036+(1-0.0036)*(1.0*with_norm), 0.0036+(1-0.0036)*(1.0*with_norm), 0.0050+(1-0.0050)*(1.0*with_norm)))\n",
    "                                    ])\n",
    "\n",
    "batch_size = 64\n",
    "testset = Hotdog_NotHotdog(train=False, transform=train_test_transform)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "# Get model\n",
    "efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0',pretrained=False)\n",
    "# Change model classifier to hotdog/notdog (don't freeze params of last layer)\n",
    "num_ftrs = efficientnet.classifier.fc.in_features\n",
    "efficientnet.classifier.fc = nn.Linear(num_ftrs, 2)\n",
    "# Freeze parameters for pretrained model (to avoid overfitting)\n",
    "efficientnet.load_state_dict(torch.load(os.getcwd()+\"/models/\"+name+\".pt\"))\n",
    "efficientnet.to(device)\n",
    "efficientnet.eval()\n",
    "\n",
    "\n",
    "# Get accuracy of each class\n",
    "test_correct = {i:0 for i in range(2)}\n",
    "test_labels = {i:0 for i in range(2)}\n",
    "for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = efficientnet(data)\n",
    "    predicted = output.argmax(1).cpu()\n",
    "    for i in range(2):\n",
    "        test_correct[i] += (target[target==i]==predicted[target==i]).sum().item()\n",
    "        test_labels[i] += (target==i).sum().item()\n",
    "\n",
    "for i in range(2):\n",
    "    test_correct[i] = test_correct[i]/test_labels[i]\n",
    "\n",
    "print(test_correct)\n",
    "\n",
    "# For wrong classifications, view the misclassifications\n",
    "test_count = 0\n",
    "plt.figure(figsize=(20,10))\n",
    "transform = transforms.ToPILImage()\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = efficientnet(data)\n",
    "    predicted = output.argmax(1).cpu()\n",
    "    for i in range(len(target)):\n",
    "        if target[i]!=predicted[i]:\n",
    "            plt.subplot(5,4,test_count+1)\n",
    "            plt.imshow(data[i].cpu().numpy()[0], 'gray')\n",
    "            plt.title(f'target: {\"hotdog\" if target[i].item() == 0 else \"notdog\"}, pred: {\"hotdog\" if predicted[i].item() == 0 else \"notdog\"}')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            test_count += 1\n",
    "    \n",
    "        if test_count == 8:\n",
    "            break;\n",
    "    if test_count == 8:\n",
    "        break;\n",
    "\n",
    "test_count += 4\n",
    "for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = efficientnet(data)\n",
    "    predicted = output.argmax(1).cpu()\n",
    "    for i in range(len(target)):\n",
    "        if target[i]==predicted[i]:\n",
    "            plt.subplot(5,4,test_count+1)\n",
    "            #convert image back to Height,Width,Channels\n",
    "            #img = np.transpose(data[i].cpu().numpy(), (1,2,0))\n",
    "            #plt.imshow(img, 'gray')\n",
    "            plt.imshow(data[i].cpu().numpy()[0], 'gray')\n",
    "            plt.title(f'target: {\"hotdog\" if target[i].item() == 0 else \"notdog\"}, pred: {\"hotdog\" if predicted[i].item() == 0 else \"notdog\"}')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            test_count += 1\n",
    "    \n",
    "        if test_count == 20:\n",
    "            break;\n",
    "    if test_count == 20:\n",
    "        break;\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.getcwd()+'/reports/figures/test_images_classified/'+name+'.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Saliency for same images\n",
    "test_count = 0\n",
    "fig, axs = plt.subplots(5,4,figsize=(12,10), gridspec_kw={'height_ratios': [1, 1, 0.3, 1, 1]})\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    data.requires_grad_()\n",
    "    output = efficientnet(data)\n",
    "    predicted = output.argmax(1).cpu()\n",
    "    \n",
    "    # Catch the output\n",
    "    output_idx = output.argmax(dim=1)\n",
    "\n",
    "    for i in range(len(target)):\n",
    "        if target[i]!=predicted[i]:\n",
    "            # Do backpropagation to get the derivative of the output based on the image\n",
    "            output_max = output[i,output_idx[i]]\n",
    "            output_max.backward(retain_graph=True)\n",
    "            saliency, _ = torch.max(data.grad.data[i].abs(), dim=0) \n",
    "            saliency = saliency.reshape(size, size)\n",
    "            saliency = (saliency-torch.min(saliency))/(torch.max(saliency)-torch.min(saliency))\n",
    "\n",
    "            axs.flatten()[test_count+4].imshow(saliency.cpu().numpy(), 'gnuplot2')\n",
    "            axs.flatten()[test_count+4].set_title(f'Saliency of prediction')\n",
    "            axs.flatten()[test_count+4].axis('off')\n",
    "\n",
    "            axs.flatten()[test_count].imshow(data[i].detach().cpu().numpy()[0], 'gray')\n",
    "            axs.flatten()[test_count].set_title(f'target: {\"hotdog\" if target[i].item() == 0 else \"notdog\"}, pred: {\"hotdog\" if predicted[i].item() == 0 else \"notdog\"}')\n",
    "            axs.flatten()[test_count].axis('off')\n",
    "\n",
    "            \n",
    "            test_count += 1\n",
    "    \n",
    "        if test_count == 4:\n",
    "            break;\n",
    "    if test_count == 4:\n",
    "        break;\n",
    "\n",
    "test_count += 8\n",
    "axs.flatten()[9].axis('off')\n",
    "axs.flatten()[10].axis('off')\n",
    "axs.flatten()[11].axis('off')\n",
    "axs.flatten()[8].axis('off')\n",
    "for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    data.requires_grad_()\n",
    "    output = efficientnet(data)\n",
    "    predicted = output.argmax(1).cpu()\n",
    "\n",
    "    # Catch the output\n",
    "    output_idx = output.argmax(dim=1)\n",
    "\n",
    "    for i in range(len(target)):\n",
    "        if target[i]==predicted[i]:\n",
    "            # Do backpropagation to get the derivative of the output based on the image\n",
    "            output_max = output[i,output_idx[i]]\n",
    "            output_max.backward(retain_graph=True)\n",
    "            saliency, _ = torch.max(data.grad.data[i].abs(), dim=0) \n",
    "            saliency = saliency.reshape(size, size)\n",
    "            saliency = (saliency-torch.min(saliency))/(torch.max(saliency)-torch.min(saliency))\n",
    "            axs.flatten()[test_count+4].imshow(saliency.cpu().numpy(), 'gnuplot2')\n",
    "            axs.flatten()[test_count+4].set_title(f'Saliency of prediction')\n",
    "            axs.flatten()[test_count+4].axis('off')\n",
    "\n",
    "            axs.flatten()[test_count].imshow(data[i].detach().cpu().numpy()[0], 'gray')\n",
    "            axs.flatten()[test_count].set_title(f'target: {\"hotdog\" if target[i].item() == 0 else \"notdog\"}, pred: {\"hotdog\" if predicted[i].item() == 0 else \"notdog\"}')\n",
    "            axs.flatten()[test_count].axis('off')\n",
    "            \n",
    "            test_count += 1\n",
    "    \n",
    "        if test_count == 16:\n",
    "            break;\n",
    "    if test_count == 16:\n",
    "        break;\n",
    "#plt.subplots_adjust(left=0.02, right=0.98, top=0.98, bottom=0.02, hspace=0.2, wspace=0.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.getcwd()+'/reports/figures/saliency_maps/'+name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
